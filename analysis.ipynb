{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold #for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score #score evaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "from sklearn import svm #support vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pclass\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "\n",
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "Ticket\n",
      "347082      7\n",
      "CA. 2343    7\n",
      "1601        7\n",
      "3101295     6\n",
      "CA 2144     6\n",
      "           ..\n",
      "9234        1\n",
      "19988       1\n",
      "2693        1\n",
      "PC 17612    1\n",
      "370376      1\n",
      "Name: Ticket, Length: 681, dtype: int64\n",
      "\n",
      "Cabin\n",
      "NaN            687\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C22 C26          3\n",
      "              ... \n",
      "E34              1\n",
      "C7               1\n",
      "C54              1\n",
      "E36              1\n",
      "C148             1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      "Embarked\n",
      "S      644\n",
      "C      168\n",
      "Q       77\n",
      "NaN      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ['Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "\n",
    "for c in cols:\n",
    "    print('\\n' + c)\n",
    "    print(train_data[c].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/l2pjq4_x1y3cmmlnwyd4x7_m0000gn/T/ipykernel_73952/3952726274.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = train_data.append(test_data)\n"
     ]
    }
   ],
   "source": [
    "all_data = train_data.append(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Ideas & To Do's\n",
    "- Add Title feat + add dummy's\n",
    "- Handle missing values in Age based on Title & Class\n",
    "- Handle missing values in Fare based on Class\n",
    "- Handle missing values in Embarked based on most common value + add dummy's\n",
    "- Drop Name, Title, Embarked & Cabin feat\n",
    "- Transform categorical vars (Ticket & Sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column name Title\n",
    "all_data[\"Title\"] = all_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr          757\n",
       "Miss        260\n",
       "Mrs         197\n",
       "Master       61\n",
       "Rev           8\n",
       "Dr            8\n",
       "Col           4\n",
       "Mlle          2\n",
       "Major         2\n",
       "Ms            2\n",
       "Lady          1\n",
       "Sir           1\n",
       "Mme           1\n",
       "Don           1\n",
       "Capt          1\n",
       "Countess      1\n",
       "Jonkheer      1\n",
       "Dona          1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr           757\n",
       "Miss         262\n",
       "Mrs          200\n",
       "Master        61\n",
       "Honor         19\n",
       "Millitary      7\n",
       "Honora         3\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate titles\n",
    "all_data[\"Title\"] = all_data[\"Title\"].replace('Mlle', 'Miss')\n",
    "all_data[\"Title\"] = all_data[\"Title\"].replace(['Mme', 'Ms'], 'Mrs')\n",
    "all_data[\"Title\"] = all_data[\"Title\"].replace(['Don','Jonkheer', 'Sir', 'Rev', 'Dr'],'Honor')\n",
    "all_data[\"Title\"] = all_data[\"Title\"].replace(['Capt', 'Major', 'Col'], 'Millitary')\n",
    "all_data[\"Title\"] = all_data[\"Title\"].replace(['Lady', 'Countess', 'Dona'], 'Honora')\n",
    "\n",
    "all_data.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "titledummies = pd.get_dummies(all_data[['Title']], prefix_sep='_')\n",
    "all_data = pd.concat([all_data, titledummies], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Fares Estimated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_Honor</th>\n",
       "      <th>Title_Honora</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Millitary</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.310532</td>\n",
       "      <td>0.014515</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.200153</td>\n",
       "      <td>0.578304</td>\n",
       "      <td>0.152788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.741745</td>\n",
       "      <td>0.119646</td>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.210862</td>\n",
       "      <td>0.072959</td>\n",
       "      <td>0.400267</td>\n",
       "      <td>0.494019</td>\n",
       "      <td>0.359921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
       "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
       "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
       "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
       "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
       "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
       "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
       "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
       "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
       "\n",
       "             Parch         Fare  Title_Honor  Title_Honora  Title_Master  \\\n",
       "count  1309.000000  1309.000000  1309.000000   1309.000000   1309.000000   \n",
       "mean      0.385027    33.310532     0.014515      0.002292      0.046600   \n",
       "std       0.865560    51.741745     0.119646      0.047836      0.210862   \n",
       "min       0.000000     0.000000     0.000000      0.000000      0.000000   \n",
       "25%       0.000000     7.895800     0.000000      0.000000      0.000000   \n",
       "50%       0.000000    14.454200     0.000000      0.000000      0.000000   \n",
       "75%       0.000000    31.275000     0.000000      0.000000      0.000000   \n",
       "max       9.000000   512.329200     1.000000      1.000000      1.000000   \n",
       "\n",
       "       Title_Millitary   Title_Miss     Title_Mr    Title_Mrs  \n",
       "count      1309.000000  1309.000000  1309.000000  1309.000000  \n",
       "mean          0.005348     0.200153     0.578304     0.152788  \n",
       "std           0.072959     0.400267     0.494019     0.359921  \n",
       "min           0.000000     0.000000     0.000000     0.000000  \n",
       "25%           0.000000     0.000000     0.000000     0.000000  \n",
       "50%           0.000000     0.000000     1.000000     0.000000  \n",
       "75%           0.000000     0.000000     1.000000     0.000000  \n",
       "max           1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate missing Fare values\n",
    "classes = np.unique(all_data.Pclass.values)\n",
    "for clss in classes:\n",
    "    fare_to_impute = all_data.groupby('Title')['Age'].median()[clss]\n",
    "    all_data.loc[(all_data['Fare'].isnull()) & (all_data['Pclass'] == clss), 'Fare'] = fare_to_impute\n",
    "print('Missing Fares Estimated')\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Ages Estimated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_Honor</th>\n",
       "      <th>Title_Honora</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Millitary</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.422972</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.310532</td>\n",
       "      <td>0.014515</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.200153</td>\n",
       "      <td>0.578304</td>\n",
       "      <td>0.152788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>13.154266</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.741745</td>\n",
       "      <td>0.119646</td>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.210862</td>\n",
       "      <td>0.072959</td>\n",
       "      <td>0.400267</td>\n",
       "      <td>0.494019</td>\n",
       "      <td>0.359921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
       "count  1309.000000  891.000000  1309.000000  1309.000000  1309.000000   \n",
       "mean    655.000000    0.383838     2.294882    29.422972     0.498854   \n",
       "std     378.020061    0.486592     0.837836    13.154266     1.041658   \n",
       "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
       "25%     328.000000    0.000000     2.000000    22.000000     0.000000   \n",
       "50%     655.000000    0.000000     3.000000    29.000000     0.000000   \n",
       "75%     982.000000    1.000000     3.000000    35.000000     1.000000   \n",
       "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
       "\n",
       "             Parch         Fare  Title_Honor  Title_Honora  Title_Master  \\\n",
       "count  1309.000000  1309.000000  1309.000000   1309.000000   1309.000000   \n",
       "mean      0.385027    33.310532     0.014515      0.002292      0.046600   \n",
       "std       0.865560    51.741745     0.119646      0.047836      0.210862   \n",
       "min       0.000000     0.000000     0.000000      0.000000      0.000000   \n",
       "25%       0.000000     7.895800     0.000000      0.000000      0.000000   \n",
       "50%       0.000000    14.454200     0.000000      0.000000      0.000000   \n",
       "75%       0.000000    31.275000     0.000000      0.000000      0.000000   \n",
       "max       9.000000   512.329200     1.000000      1.000000      1.000000   \n",
       "\n",
       "       Title_Millitary   Title_Miss     Title_Mr    Title_Mrs  \n",
       "count      1309.000000  1309.000000  1309.000000  1309.000000  \n",
       "mean          0.005348     0.200153     0.578304     0.152788  \n",
       "std           0.072959     0.400267     0.494019     0.359921  \n",
       "min           0.000000     0.000000     0.000000     0.000000  \n",
       "25%           0.000000     0.000000     0.000000     0.000000  \n",
       "50%           0.000000     0.000000     1.000000     0.000000  \n",
       "75%           0.000000     0.000000     1.000000     0.000000  \n",
       "max           1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate missing Age values\n",
    "titles = np.unique(all_data.Title.values)\n",
    "for title in titles:\n",
    "    age_to_impute = all_data.groupby('Title')['Age'].median()[title]\n",
    "    all_data.loc[(all_data['Age'].isnull()) & (all_data['Title'] == title), 'Age'] = age_to_impute\n",
    "print('Missing Ages Estimated')\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate missing Embarked values\n",
    "all_data[\"Embarked\"] = all_data[\"Embarked\"].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "embarked_dummies = pd.get_dummies(all_data[['Embarked']], prefix_sep='_')\n",
    "all_data = pd.concat([all_data, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Cabin', 'Name', 'Title', 'Embarked']\n",
    "\n",
    "for c in columns_to_drop:\n",
    "    all_data = all_data.drop([c], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_Honor</th>\n",
       "      <th>Title_Honora</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Millitary</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>816</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>914</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>649</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch  Ticket     Fare  \\\n",
       "0            1       0.0       3    1  22.0      1      0     720   7.2500   \n",
       "1            2       1.0       1    0  38.0      1      0     816  71.2833   \n",
       "2            3       1.0       3    0  26.0      0      0     914   7.9250   \n",
       "3            4       1.0       1    0  35.0      1      0      65  53.1000   \n",
       "4            5       0.0       3    1  35.0      0      0     649   8.0500   \n",
       "\n",
       "   Title_Honor  Title_Honora  Title_Master  Title_Millitary  Title_Miss  \\\n",
       "0            0             0             0                0           0   \n",
       "1            0             0             0                0           0   \n",
       "2            0             0             0                0           1   \n",
       "3            0             0             0                0           0   \n",
       "4            0             0             0                0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0           0           0           1  \n",
       "1         0          1           1           0           0  \n",
       "2         0          0           0           0           1  \n",
       "3         0          1           0           0           1  \n",
       "4         1          0           0           0           1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feat in ['Ticket', 'Sex']:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le = le.fit(all_data[feat])\n",
    "    all_data[feat] = le.transform(all_data[feat])\n",
    "    \n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_Honor</th>\n",
       "      <th>Title_Honora</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Millitary</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>816</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>914</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>649</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch  Ticket     Fare  \\\n",
       "0            1       0.0       3    1  22.0      1      0     720   7.2500   \n",
       "1            2       1.0       1    0  38.0      1      0     816  71.2833   \n",
       "2            3       1.0       3    0  26.0      0      0     914   7.9250   \n",
       "3            4       1.0       1    0  35.0      1      0      65  53.1000   \n",
       "4            5       0.0       3    1  35.0      0      0     649   8.0500   \n",
       "\n",
       "   Title_Honor  Title_Honora  Title_Master  Title_Millitary  Title_Miss  \\\n",
       "0            0             0             0                0           0   \n",
       "1            0             0             0                0           0   \n",
       "2            0             0             0                0           1   \n",
       "3            0             0             0                0           0   \n",
       "4            0             0             0                0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0           0           0           1  \n",
       "1         0          1           1           0           0  \n",
       "2         0          0           0           0           1  \n",
       "3         0          1           0           0           1  \n",
       "4         1          0           0           0           1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = all_data[:891]\n",
    "test_data = all_data[891:]\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_Honor</th>\n",
       "      <th>Title_Honora</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Millitary</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>366</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>338</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex   Age  SibSp  Parch  Ticket     Fare  Title_Honor  \\\n",
       "0          892       3    1  34.5      0      0     376   7.8292            0   \n",
       "1          893       3    0  47.0      1      0     582   7.0000            0   \n",
       "2          894       2    1  62.0      0      0     184   9.6875            0   \n",
       "3          895       3    1  27.0      0      0     366   8.6625            0   \n",
       "4          896       3    0  22.0      1      1     338  12.2875            0   \n",
       "\n",
       "   Title_Honora  Title_Master  Title_Millitary  Title_Miss  Title_Mr  \\\n",
       "0             0             0                0           0         1   \n",
       "1             0             0                0           0         0   \n",
       "2             0             0                0           0         1   \n",
       "3             0             0                0           0         1   \n",
       "4             0             0                0           0         0   \n",
       "\n",
       "   Title_Mrs  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0          0           0           1           0  \n",
       "1          1           0           0           1  \n",
       "2          0           0           1           0  \n",
       "3          0           0           0           1  \n",
       "4          1           0           0           1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.drop(['Survived'], axis = 1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Models to try\n",
    "- logistic regression\n",
    "- catboost\n",
    "\n",
    "Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = train_data.drop(['Survived', 'PassengerId'], axis=1)\n",
    "target = train_data[\"Survived\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score for logistic regression is: 81.26801152737752 %\n",
      "Validation accuracy 0.868020304568528\n"
     ]
    }
   ],
   "source": [
    "print('The training score for logistic regression is:',(model1.score(X_train,y_train)*100),'%')\n",
    "print('Validation accuracy', accuracy_score(y_val, model1.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=6)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "model2 = RandomForestClassifier(n_estimators=6)\n",
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score for Random Forests is: 96.25360230547551 %\n",
      "Validation accuracy 0.8527918781725888\n"
     ]
    }
   ],
   "source": [
    "print('The training score for Random Forests is:',(model2.score(X_train,y_train)*100),'%')\n",
    "print('Validation accuracy', accuracy_score(y_val, model2.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=1.1, n_estimators=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1.1, n_estimators=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.1, n_estimators=7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "model3 = GradientBoostingClassifier(n_estimators=7,learning_rate=1.1)\n",
    "model3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score for Gradient Boosting is: 88.76080691642652 %\n",
      "Validation accuracy 0.868020304568528\n"
     ]
    }
   ],
   "source": [
    "print('The training score for Gradient Boosting is:',(model3.score(X_train,y_train)*100),'%')\n",
    "print('Validation accuracy', accuracy_score(y_val, model3.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4717101\ttotal: 56.9ms\tremaining: 512ms\n",
      "1:\tlearn: 0.4308688\ttotal: 57.8ms\tremaining: 231ms\n",
      "2:\tlearn: 0.4066799\ttotal: 58.4ms\tremaining: 136ms\n",
      "3:\tlearn: 0.3905088\ttotal: 59.1ms\tremaining: 88.6ms\n",
      "4:\tlearn: 0.3791518\ttotal: 59.8ms\tremaining: 59.8ms\n",
      "5:\tlearn: 0.3762493\ttotal: 60.7ms\tremaining: 40.5ms\n",
      "6:\tlearn: 0.3584344\ttotal: 61.3ms\tremaining: 26.3ms\n",
      "7:\tlearn: 0.3531904\ttotal: 62ms\tremaining: 15.5ms\n",
      "8:\tlearn: 0.3419583\ttotal: 62.7ms\tremaining: 6.97ms\n",
      "9:\tlearn: 0.3366420\ttotal: 63.5ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1321fe390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = CatBoostClassifier(iterations=10,\n",
    "                           learning_rate=1.1)\n",
    "model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score for CatBoost is: 87.31988472622479 %\n",
      "Validation accuracy 0.8578680203045685\n"
     ]
    }
   ],
   "source": [
    "print('The training score for CatBoost is:',(model4.score(X_train,y_train)*100),'%')\n",
    "print('Validation accuracy', accuracy_score(y_val, model4.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/marnix/opt/anaconda3/envs/titanic/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4330073\ttotal: 3.15ms\tremaining: 28.3ms\n",
      "1:\tlearn: 0.4019915\ttotal: 3.88ms\tremaining: 15.5ms\n",
      "2:\tlearn: 0.3751029\ttotal: 4.53ms\tremaining: 10.6ms\n",
      "3:\tlearn: 0.3728277\ttotal: 4.92ms\tremaining: 7.38ms\n",
      "4:\tlearn: 0.3644611\ttotal: 5.55ms\tremaining: 5.55ms\n",
      "5:\tlearn: 0.3549655\ttotal: 6.12ms\tremaining: 4.08ms\n",
      "6:\tlearn: 0.3458087\ttotal: 6.97ms\tremaining: 2.99ms\n",
      "7:\tlearn: 0.3427093\ttotal: 7.54ms\tremaining: 1.89ms\n",
      "8:\tlearn: 0.3355943\ttotal: 8.18ms\tremaining: 908us\n",
      "9:\tlearn: 0.3291469\ttotal: 8.88ms\tremaining: 0us\n",
      "0:\tlearn: 0.4327438\ttotal: 627us\tremaining: 5.64ms\n",
      "1:\tlearn: 0.3917810\ttotal: 1.23ms\tremaining: 4.91ms\n",
      "2:\tlearn: 0.3762182\ttotal: 1.72ms\tremaining: 4ms\n",
      "3:\tlearn: 0.3656373\ttotal: 2.22ms\tremaining: 3.33ms\n",
      "4:\tlearn: 0.3574130\ttotal: 2.79ms\tremaining: 2.79ms\n",
      "5:\tlearn: 0.3516546\ttotal: 3.28ms\tremaining: 2.19ms\n",
      "6:\tlearn: 0.3444710\ttotal: 3.78ms\tremaining: 1.62ms\n",
      "7:\tlearn: 0.3311504\ttotal: 4.4ms\tremaining: 1.1ms\n",
      "8:\tlearn: 0.3221821\ttotal: 4.89ms\tremaining: 543us\n",
      "9:\tlearn: 0.3171764\ttotal: 5.48ms\tremaining: 0us\n",
      "0:\tlearn: 0.4324321\ttotal: 573us\tremaining: 5.17ms\n",
      "1:\tlearn: 0.3968594\ttotal: 1.05ms\tremaining: 4.19ms\n",
      "2:\tlearn: 0.3820847\ttotal: 1.54ms\tremaining: 3.6ms\n",
      "3:\tlearn: 0.3804442\ttotal: 1.84ms\tremaining: 2.76ms\n",
      "4:\tlearn: 0.3681770\ttotal: 2.39ms\tremaining: 2.39ms\n",
      "5:\tlearn: 0.3565244\ttotal: 2.88ms\tremaining: 1.92ms\n",
      "6:\tlearn: 0.3409908\ttotal: 3.39ms\tremaining: 1.45ms\n",
      "7:\tlearn: 0.3366014\ttotal: 3.87ms\tremaining: 967us\n",
      "8:\tlearn: 0.3290731\ttotal: 4.36ms\tremaining: 484us\n",
      "9:\tlearn: 0.3141740\ttotal: 4.86ms\tremaining: 0us\n",
      "0:\tlearn: 0.4523479\ttotal: 1.27ms\tremaining: 11.4ms\n",
      "1:\tlearn: 0.4112810\ttotal: 1.81ms\tremaining: 7.25ms\n",
      "2:\tlearn: 0.3892958\ttotal: 2.32ms\tremaining: 5.42ms\n",
      "3:\tlearn: 0.3825817\ttotal: 2.59ms\tremaining: 3.89ms\n",
      "4:\tlearn: 0.3751694\ttotal: 3.15ms\tremaining: 3.15ms\n",
      "5:\tlearn: 0.3648962\ttotal: 3.67ms\tremaining: 2.45ms\n",
      "6:\tlearn: 0.3559378\ttotal: 4.14ms\tremaining: 1.77ms\n",
      "7:\tlearn: 0.3529785\ttotal: 4.62ms\tremaining: 1.15ms\n",
      "8:\tlearn: 0.3493303\ttotal: 5.09ms\tremaining: 565us\n",
      "9:\tlearn: 0.3428007\ttotal: 5.65ms\tremaining: 0us\n",
      "0:\tlearn: 0.4524003\ttotal: 730us\tremaining: 6.58ms\n",
      "1:\tlearn: 0.4246643\ttotal: 1.45ms\tremaining: 5.79ms\n",
      "2:\tlearn: 0.4000010\ttotal: 1.77ms\tremaining: 4.13ms\n",
      "3:\tlearn: 0.3915187\ttotal: 2.28ms\tremaining: 3.43ms\n",
      "4:\tlearn: 0.3783229\ttotal: 2.81ms\tremaining: 2.81ms\n",
      "5:\tlearn: 0.3638541\ttotal: 3.32ms\tremaining: 2.21ms\n",
      "6:\tlearn: 0.3579213\ttotal: 3.76ms\tremaining: 1.61ms\n",
      "7:\tlearn: 0.3505995\ttotal: 4.37ms\tremaining: 1.09ms\n",
      "8:\tlearn: 0.3404613\ttotal: 4.92ms\tremaining: 546us\n",
      "9:\tlearn: 0.3365964\ttotal: 5.51ms\tremaining: 0us\n",
      "0:\tlearn: 0.4355664\ttotal: 661us\tremaining: 5.95ms\n",
      "1:\tlearn: 0.3990769\ttotal: 1.14ms\tremaining: 4.56ms\n",
      "2:\tlearn: 0.3825923\ttotal: 1.59ms\tremaining: 3.72ms\n",
      "3:\tlearn: 0.3802076\ttotal: 1.9ms\tremaining: 2.85ms\n",
      "4:\tlearn: 0.3684958\ttotal: 2.38ms\tremaining: 2.38ms\n",
      "5:\tlearn: 0.3594281\ttotal: 2.82ms\tremaining: 1.88ms\n",
      "6:\tlearn: 0.3549768\ttotal: 3.38ms\tremaining: 1.45ms\n",
      "7:\tlearn: 0.3458993\ttotal: 4.06ms\tremaining: 1.01ms\n",
      "8:\tlearn: 0.3325483\ttotal: 5.56ms\tremaining: 618us\n",
      "9:\tlearn: 0.3258007\ttotal: 6.11ms\tremaining: 0us\n",
      "0:\tlearn: 0.4600985\ttotal: 825us\tremaining: 7.43ms\n",
      "1:\tlearn: 0.3947602\ttotal: 1.28ms\tremaining: 5.14ms\n",
      "2:\tlearn: 0.3793476\ttotal: 1.78ms\tremaining: 4.14ms\n",
      "3:\tlearn: 0.3649294\ttotal: 2.26ms\tremaining: 3.39ms\n",
      "4:\tlearn: 0.3554118\ttotal: 2.8ms\tremaining: 2.8ms\n",
      "5:\tlearn: 0.3540090\ttotal: 3.31ms\tremaining: 2.21ms\n",
      "6:\tlearn: 0.3419833\ttotal: 3.82ms\tremaining: 1.64ms\n",
      "7:\tlearn: 0.3320238\ttotal: 4.3ms\tremaining: 1.07ms\n",
      "8:\tlearn: 0.3264347\ttotal: 4.84ms\tremaining: 537us\n",
      "9:\tlearn: 0.3243100\ttotal: 5.35ms\tremaining: 0us\n",
      "0:\tlearn: 0.4304606\ttotal: 580us\tremaining: 5.22ms\n",
      "1:\tlearn: 0.3941754\ttotal: 1.14ms\tremaining: 4.57ms\n",
      "2:\tlearn: 0.3821259\ttotal: 1.77ms\tremaining: 4.14ms\n",
      "3:\tlearn: 0.3697773\ttotal: 2.36ms\tremaining: 3.54ms\n",
      "4:\tlearn: 0.3624832\ttotal: 2.84ms\tremaining: 2.84ms\n",
      "5:\tlearn: 0.3563186\ttotal: 3.31ms\tremaining: 2.21ms\n",
      "6:\tlearn: 0.3422580\ttotal: 3.92ms\tremaining: 1.68ms\n",
      "7:\tlearn: 0.3314556\ttotal: 4.46ms\tremaining: 1.11ms\n",
      "8:\tlearn: 0.3218245\ttotal: 5.14ms\tremaining: 571us\n",
      "9:\tlearn: 0.3173181\ttotal: 5.66ms\tremaining: 0us\n",
      "0:\tlearn: 0.4429407\ttotal: 592us\tremaining: 5.34ms\n",
      "1:\tlearn: 0.4050085\ttotal: 1.07ms\tremaining: 4.29ms\n",
      "2:\tlearn: 0.3914144\ttotal: 1.6ms\tremaining: 3.74ms\n",
      "3:\tlearn: 0.3804175\ttotal: 2.34ms\tremaining: 3.5ms\n",
      "4:\tlearn: 0.3705241\ttotal: 2.93ms\tremaining: 2.93ms\n",
      "5:\tlearn: 0.3627955\ttotal: 3.41ms\tremaining: 2.27ms\n",
      "6:\tlearn: 0.3529277\ttotal: 3.96ms\tremaining: 1.7ms\n",
      "7:\tlearn: 0.3444181\ttotal: 4.45ms\tremaining: 1.11ms\n",
      "8:\tlearn: 0.3407728\ttotal: 4.96ms\tremaining: 551us\n",
      "9:\tlearn: 0.3352262\ttotal: 5.43ms\tremaining: 0us\n",
      "0:\tlearn: 0.4393645\ttotal: 1.27ms\tremaining: 11.5ms\n",
      "1:\tlearn: 0.4082740\ttotal: 1.83ms\tremaining: 7.31ms\n",
      "2:\tlearn: 0.3844162\ttotal: 2.33ms\tremaining: 5.44ms\n",
      "3:\tlearn: 0.3723701\ttotal: 2.84ms\tremaining: 4.26ms\n",
      "4:\tlearn: 0.3645330\ttotal: 3.33ms\tremaining: 3.33ms\n",
      "5:\tlearn: 0.3608307\ttotal: 3.88ms\tremaining: 2.58ms\n",
      "6:\tlearn: 0.3528685\ttotal: 5.11ms\tremaining: 2.19ms\n",
      "7:\tlearn: 0.3454500\ttotal: 5.57ms\tremaining: 1.39ms\n",
      "8:\tlearn: 0.3369028\ttotal: 6.13ms\tremaining: 681us\n",
      "9:\tlearn: 0.3331944\ttotal: 6.7ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.817091</td>\n",
       "      <td>0.036754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.830574</td>\n",
       "      <td>0.043122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.821561</td>\n",
       "      <td>0.031484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.835019</td>\n",
       "      <td>0.023575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CV Mean       Std\n",
       "Logistic Regression  0.817091  0.036754\n",
       "Random Forest        0.830574  0.043122\n",
       "GradientBoosting     0.821561  0.031484\n",
       "CatBoost             0.835019  0.023575"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10) # k=10, split the data into 10 equal parts\n",
    "xyz=[]\n",
    "accuracy=[]\n",
    "std=[]\n",
    "test_data = test_data.dropna()\n",
    "classifiers=['Logistic Regression', 'Random Forest', 'GradientBoosting', 'CatBoost']\n",
    "models=[LogisticRegression(),RandomForestClassifier(n_estimators=100),GradientBoostingClassifier(n_estimators=7,learning_rate=1.1),\n",
    "        CatBoostClassifier(iterations=10, learning_rate=1.1)]\n",
    "for i in models:\n",
    "    model = i\n",
    "    cv_result = cross_val_score(model,predictors,target, cv = kfold,scoring = \"accuracy\")\n",
    "    cv_result=cv_result\n",
    "    xyz.append(cv_result.mean())\n",
    "    std.append(cv_result.std())\n",
    "    accuracy.append(cv_result)\n",
    "new_models_dataframe2=pd.DataFrame({'CV Mean':xyz,'Std':std},index=classifiers)       \n",
    "new_models_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(12,6))\n",
    "box=pd.DataFrame(accuracy,index=[classifiers])\n",
    "box.T.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = test_data.PassengerId\n",
    "test_data = test_data.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = model1.predict(test_data)\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': prediction1.astype(int) } )\n",
    "filename = 'titanic_pred_' + 'LogReg' + '.csv'\n",
    "test.to_csv( filename , index = False )\n",
    "\n",
    "\n",
    "prediction2 = model2.predict(test_data)\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': prediction2.astype(int) } )\n",
    "filename = 'titanic_pred_' + 'RandForest' + '.csv'\n",
    "test.to_csv( filename , index = False )\n",
    "\n",
    "\n",
    "prediction3 = model3.predict(test_data)\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': prediction3.astype(int) } )\n",
    "filename = 'titanic_pred_' + 'GradBoost' + '.csv'\n",
    "test.to_csv( filename , index = False )\n",
    "\n",
    "\n",
    "prediction4 = model4.predict(test_data)\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': prediction4.astype(int) } )\n",
    "filename = 'titanic_pred_' + 'CatBoost' + '.csv'\n",
    "test.to_csv( filename , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('titanic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c460c809b2359af7b59120089800d577597e818edb55785b6d1f9236f678ea9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
